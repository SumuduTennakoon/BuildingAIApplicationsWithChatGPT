{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80YnPM-vhaCm"
      },
      "source": [
        "\n",
        "# Building AI Applications with ChatGPT\n",
        "\n",
        "Sumudu Tennakoon, PhD\n",
        "<hr>\n",
        "\n",
        "# NLP With OpenSource Language Models\n",
        "\n",
        "In this notebook we will explore some basic fetures on Python programing language for those who have a prior programing expereince.\n",
        "\n",
        "To learn more about Python, refeer to the following websites\n",
        "\n",
        "- Python : https://www.python.org\n",
        "\n",
        "To learn more about the Python packages we explore in this notebook, refer to the following websites\n",
        "\n",
        "- HuggingFace : https://huggingface.co\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yexZBDVRcHBA"
      },
      "source": [
        "# Getting Started with HuggingFace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Run below code cell to install required libraries before you continue. Ignore that if you already installed them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install transformers sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pipelines\n",
        "\n",
        "* HuggingFace pipelines  streamlined interface for common NLP tasks, such as sentiment analysis, text classification, named entity recognition, and text generation, speech-recognition. \n",
        "* You can choose from many different models and tasks on the HuggingFace website. \n",
        "* Pipelines make it easy to use models without writing a lot of code.*\n",
        "\n",
        "https://huggingface.co/docs/transformers/main_classes/pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WDu4H38cRuo",
        "outputId": "c2cba806-b513-4b0c-ac50-3af0be4afd3d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9986220598220825}]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline('sentiment-analysis')\n",
        "classifier('I enojoy watching this movie!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'NEG', 'score': 0.9834356904029846}]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier = pipeline('sentiment-analysis', model=\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
        "classifier('This movie was the worst in the series!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question Answering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uYTLhvU3jd7q",
        "outputId": "20c01332-383d-491b-e726-ed0df188b751"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'score': 0.9644644856452942,\n",
              " 'start': 58,\n",
              " 'end': 74,\n",
              " 'answer': 'November 7, 1867'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "nlp = pipeline(\"question-answering\")\n",
        "\n",
        "context = \"\"\" Marie Curie, née Maria Sklodowska, was born in Warsaw on November 7, \\\n",
        "1867, the daughter of a secondary-school teacher. She received a general education \\\n",
        "in local schools and some scientific training from her father. She became involved \\\n",
        "in a students’ revolutionary organization and found it prudent to leave Warsaw, then \\\n",
        "in the part of Poland dominated by Russia, for Cracow, which at that time was under \\\n",
        "Austrian rule. In 1891, she went to Paris to continue her studies at the Sorbonne \\\n",
        "where she obtained Licenciateships in Physics and the Mathematical Sciences. She met \\\n",
        "Pierre Curie, Professor in the School of Physics in 1894 and in the following year \\\n",
        "they were married. She succeeded her husband as Head of the Physics Laboratory at \\\n",
        "the Sorbonne, gained her Doctor of Science degree in 1903, and following the tragic \\\n",
        "death of Pierre Curie in 1906, she took his place as Professor of General Physics in \\\n",
        "the Faculty of Sciences, the first time a woman had held this position. She was also \\\n",
        "appointed Director of the Curie Laboratory in the Radium Institute of the University \\\n",
        "of Paris, founded in 1914.\n",
        "\"\"\"\n",
        "\n",
        "nlp(question=\"When did Marie Curie Born?\", context=context)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'score': 0.4384763538837433,\n",
              " 'start': 1001,\n",
              " 'end': 1033,\n",
              " 'answer': 'Director of the Curie Laboratory'}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nlp(question=\"What are the positions Marie Curie held at University of Paris?\", context=context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Specify Model and Reuse Pipleline for Multiple Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'question': 'When did Marie Curie Born?', 'response': {'score': 0.9599596858024597, 'start': 58, 'end': 74, 'answer': 'November 7, 1867'}}\n",
            "{'question': 'What are the positions Marie Curie held at University of Paris?', 'response': {'score': 0.19194874167442322, 'start': 1001, 'end': 1033, 'answer': 'Director of the Curie Laboratory'}}\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "nlp = pipeline(\"question-answering\", model='deepset/roberta-base-squad2')\n",
        "\n",
        "question = \"When did Marie Curie Born?\"\n",
        "response = nlp(question=question, context=context)\n",
        "print({\"question\":question, \"response\": response})\n",
        "\n",
        "question = \"What are the positions Marie Curie held at University of Paris?\"\n",
        "response = nlp(question=question, context=context)\n",
        "print({\"question\":question, \"response\": response})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW-hIaBMjb-v",
        "outputId": "eccd7042-c14e-493e-a567-e697e3da1fc5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'generated_text': 'An apple fell from the tree'}]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "text_generator = pipeline(\"text-generation\")\n",
        "text_generator(\"An apple fell from the\", max_length=6, do_sample=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'generated_text': 'An apple fell from the sky and was knocked to the ground in a hail of rain. The angel'}]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Extend the length of Generated Sequence\n",
        "\n",
        "text_generator(\"An apple fell from the\", max_length=20, do_sample=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\TeachingWorkspace\\GitHub\\BuildingAIApplicationsWithChatGPT-main\\.venv\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'translation_text': 'Bonjour, comment allez-vous ?'}]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "text = \"Hello. How are you?\"\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-fr\")\n",
        "\n",
        "translator(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'translation_text': 'Hi, how are you?'}]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "text = \"Hola cómo estás?\"\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-es-en\")\n",
        "\n",
        "translator(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'summary_text': 'Marie Curie, née Maria Sklodowska, was born in Warsaw on November 7, 1867. She received a general education in local schools and some scientific training from her father. In 1891, she went to Paris to continue her studies at the Sorbonne where she obtained Licenciateships in Physics and the Mathematical Sciences.'}]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "text = \"\"\" Marie Curie, née Maria Sklodowska, was born in Warsaw on November 7, \\\n",
        "1867, the daughter of a secondary-school teacher. She received a general education \\\n",
        "in local schools and some scientific training from her father. She became involved \\\n",
        "in a students’ revolutionary organization and found it prudent to leave Warsaw, then \\\n",
        "in the part of Poland dominated by Russia, for Cracow, which at that time was under \\\n",
        "Austrian rule. In 1891, she went to Paris to continue her studies at the Sorbonne \\\n",
        "where she obtained Licenciateships in Physics and the Mathematical Sciences. She met \\\n",
        "Pierre Curie, Professor in the School of Physics in 1894 and in the following year \\\n",
        "they were married. She succeeded her husband as Head of the Physics Laboratory at \\\n",
        "the Sorbonne, gained her Doctor of Science degree in 1903, and following the tragic \\\n",
        "death of Pierre Curie in 1906, she took his place as Professor of General Physics in \\\n",
        "the Faculty of Sciences, the first time a woman had held this position. She was also \\\n",
        "appointed Director of the Curie Laboratory in the Radium Institute of the University \\\n",
        "of Paris, founded in 1914.\n",
        "\"\"\"\n",
        "\n",
        "summarizer(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sequence': 'Today I am going to prepare a dinner for my friends',\n",
              " 'labels': ['cooking', 'learning', 'playing', 'travel'],\n",
              " 'scores': [0.9570969343185425,\n",
              "  0.035653986036777496,\n",
              "  0.005505905486643314,\n",
              "  0.001743113505654037]}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "sequence_to_classify = \"Today I am going to prepare a dinner for my friends\"\n",
        "\n",
        "candidate_labels = ['travel', 'cooking', 'playing', 'learning']\n",
        "\n",
        "classifier(sequence_to_classify, candidate_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sequence': 'I am going to visit Paris next year',\n",
              " 'labels': ['travel', 'learning', 'playing', 'cooking'],\n",
              " 'scores': [0.7273193597793579,\n",
              "  0.1763770431280136,\n",
              "  0.09052826464176178,\n",
              "  0.005775331985205412]}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence_to_classify = \"I am going to visit Paris next year\"\n",
        "\n",
        "candidate_labels = ['travel', 'cooking', 'playing', 'learning']\n",
        "\n",
        "classifier(sequence_to_classify, candidate_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sequence': 'I scored 75 runs in the cricket match yesterday',\n",
              " 'labels': ['playing', 'learning', 'travel', 'cooking'],\n",
              " 'scores': [0.81123948097229,\n",
              "  0.1423066407442093,\n",
              "  0.030837208032608032,\n",
              "  0.015616626478731632]}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequence_to_classify = \"I scored 75 runs in the cricket match yesterday\"\n",
        "\n",
        "candidate_labels = ['travel', 'cooking', 'playing', 'learning']\n",
        "\n",
        "classifier(sequence_to_classify, candidate_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conversation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL = \"microsoft/GODEL-v1_1-large-seq2seq\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### No Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[21035,    10,   787,     3,     9, 13463,  2625,     6,    25,   174,\n",
            "            12,  1773, 13931,     5, 18185,  1525,    12,    80,  7142,   784,\n",
            "         17752,  3463,     4,   382,   908,  1615,     8,  5796,    19,  1692,\n",
            "            58,   784,   439, 12038, 17717,  5042,   908,     1]])\n",
            "tensor([[   0,   37, 3412,   63,  774,   19,  147,   21,    8,   97,  230,    5,\n",
            "            1]])\n",
            "Instruction: given a dialog context, you need to response professionally. Limit answer to one sentence\n",
            "[CONTEXT] Why the sky is blue?\n",
            "[KNOWLEDGE] \n",
            "The rainy season is over for the time now.\n"
          ]
        }
      ],
      "source": [
        "instruction = f'Instruction: given a dialog context, you need to response professionally. Limit answer to one sentence'\n",
        "\n",
        "question = 'Why the sky is blue?'\n",
        "\n",
        "context = ''\n",
        "\n",
        "prompt = f\"{instruction}\\n[CONTEXT] {question}\\n[KNOWLEDGE] {context}\"\n",
        "\n",
        "input_ids = tokenizer(f\"{prompt}\", return_tensors=\"pt\").input_ids\n",
        "\n",
        "outputs = model.generate(input_ids, max_length=30, min_length=8, top_p=1.0, do_sample=True)\n",
        "\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(input_ids)\n",
        "print(outputs)\n",
        "print(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### With Scientific Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instruction: given a dialog context, you need to response professionally. Limit answer to one sentence\n",
            "[CONTEXT] Why the sky is blue?\n",
            "[KNOWLEDGE] \n",
            "A portion of the beam of light coming from the sun scatters off molecules of gas and other small particles in the atmosphere. Here, Rayleigh scattering primarily occurs through sunlight's interaction with randomly located air molecules. It is this scattered light that gives the surrounding sky its brightness and its color. As previously stated, Rayleigh scattering is inversely proportional to the fourth power of wavelength, so that shorter wavelength violet and blue light will scatter more than the longer wavelengths (yellow and especially red light).\n",
            "\n",
            "Rayleigh scattering is a process where light is scattered off molecules of gas and other small particles in the atmosphere.\n"
          ]
        }
      ],
      "source": [
        "instruction = f'Instruction: given a dialog context, you need to response professionally. Limit answer to one sentence'\n",
        "\n",
        "context = \"\"\"\n",
        "A portion of the beam of light coming from the sun scatters off molecules of gas and other \\\n",
        "small particles in the atmosphere. Here, Rayleigh scattering primarily occurs through \\\n",
        "sunlight's interaction with randomly located air molecules. It is this scattered light that \\\n",
        "gives the surrounding sky its brightness and its color. As previously stated, Rayleigh \\\n",
        "scattering is inversely proportional to the fourth power of wavelength, so that shorter \\\n",
        "wavelength violet and blue light will scatter more than the longer wavelengths (yellow and \\\n",
        "especially red light).\n",
        "\"\"\"\n",
        "\n",
        "question = 'Why the sky is blue?'\n",
        "\n",
        "prompt = f\"{instruction}\\n[CONTEXT] {question}\\n[KNOWLEDGE] {context}\"\n",
        "\n",
        "input_ids = tokenizer(f\"{prompt}\", return_tensors=\"pt\").input_ids\n",
        "\n",
        "outputs = model.generate(input_ids, max_length=30, min_length=8, top_p=1.0, do_sample=False)\n",
        "\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### With Greek Mythology as Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instruction: given a dialog context, you need to response professionally. Limit answer to one sentence\n",
            "[CONTEXT] Why the sky is blue?\n",
            "[KNOWLEDGE] \n",
            "The story goes that one day Zeus, the Greek god of the sky, asked his daughter Athena to make a wish. The blue-eyed Athena, wrapped up in herself, wished that the world could see her beauty every single day. Zeus granted Athena’s wish by turning the sky in blue, the color of her beautiful eyes.\n",
            "\n",
            "Zeus granted Athena’s wish to turn the sky blue, the color of her blue eyes.\n"
          ]
        }
      ],
      "source": [
        "instruction = f'Instruction: given a dialog context, you need to response professionally. Limit answer to one sentence'\n",
        "context = \"\"\"\n",
        "The story goes that one day Zeus, the Greek god of the sky, asked his daughter Athena \\\n",
        "to make a wish. The blue-eyed Athena, wrapped up in herself, wished that the world \\\n",
        "could see her beauty every single day. Zeus granted Athena’s wish by turning the sky \\\n",
        "in blue, the color of her beautiful eyes.\n",
        "\"\"\"\n",
        "\n",
        "question = 'Why the sky is blue?'\n",
        "\n",
        "prompt = f\"{instruction}\\n[CONTEXT] {question}\\n[KNOWLEDGE] {context}\"\n",
        "\n",
        "input_ids = tokenizer(f\"{prompt}\", return_tensors=\"pt\").input_ids\n",
        "\n",
        "outputs = model.generate(input_ids, max_length=30, min_length=8, top_p=1.0, do_sample=True)\n",
        "\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcOzk1VYhVpQ"
      },
      "source": [
        "<hr/>\n",
        "First Upload 2023-07-04 | Last update 2023-12-15 by Sumudu Tennakoon\n",
        "\n",
        "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
