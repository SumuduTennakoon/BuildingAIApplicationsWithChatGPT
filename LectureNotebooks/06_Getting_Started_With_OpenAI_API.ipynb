{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Building AI Applications with ChatGPT\n",
    "\n",
    "Sumudu Tennakoon, PhD\n",
    "<hr>\n",
    "\n",
    "# Getting Started With ChatGPT API\n",
    "\n",
    "In this notebook we will explore some basic fetures on Python programing language for those who have a prior programing expereince.\n",
    "\n",
    "To learn more about Python, refeer to the following websites\n",
    "\n",
    "- Python : https://www.python.org\n",
    "\n",
    "To learn more about the Python packages we explore in this notebook, refer to the following websites\n",
    "\n",
    "- OpenAI API : https://platform.openai.com/docs/api-reference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer/Encoder \n",
    "### Text to Numeric Representation of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\"You can think of tokens as pieces of words, where 1,000 tokens is about 750 words.\"```\n",
    "\n",
    "https://openai.com/pricing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tiktoken`  BPE (Byte pair encoding) tokeniser for use with OpenAI's models.\n",
    "* https://github.com/openai/tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12331,\n",
       " 648,\n",
       " 13182,\n",
       " 648,\n",
       " 574,\n",
       " 264,\n",
       " 83323,\n",
       " 323,\n",
       " 8590,\n",
       " 380,\n",
       " 889,\n",
       " 13375,\n",
       " 71674,\n",
       " 3495,\n",
       " 389,\n",
       " 9063,\n",
       " 7323,\n",
       " 323,\n",
       " 2834,\n",
       " 1403,\n",
       " 48078,\n",
       " 2394,\n",
       " 4861,\n",
       " 13]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "text = \"Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity and won two Nobel Prizes.\"\n",
    "\n",
    "tokens = encoding.encode(text)\n",
    "\n",
    "tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count Tokens\n",
    "num_tokens = # Type your code here \n",
    "\n",
    "num_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity and won two Nobel Prizes.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full Text\n",
    "\n",
    "decoded_tokens_text = encoding.decode(tokens)\n",
    "\n",
    "decoded_tokens_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'Mar',\n",
       " b'ie',\n",
       " b' Cur',\n",
       " b'ie',\n",
       " b' was',\n",
       " b' a',\n",
       " b' physicist',\n",
       " b' and',\n",
       " b' chem',\n",
       " b'ist',\n",
       " b' who',\n",
       " b' conducted',\n",
       " b' pioneering',\n",
       " b' research',\n",
       " b' on',\n",
       " b' radio',\n",
       " b'activity',\n",
       " b' and',\n",
       " b' won',\n",
       " b' two',\n",
       " b' Nobel',\n",
       " b' Pr',\n",
       " b'izes',\n",
       " b'.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By token\n",
    "\n",
    "decoded_tokens_list = [encoding.decode_single_token_bytes(token) for token in tokens]\n",
    "\n",
    "decoded_tokens_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Completion\n",
    "* Need OpenAI API Key \n",
    "  - Adds a cost per 1000 tokens after free trial period (https://openai.com/pricing)\n",
    "  - GPT-3.5 Turbo (4K context): \tInput =\t$0.0015 / 1K tokens, Output =\t$0.002 / 1K tokens (2023-07-09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(r'../../../config.ini') #Change to your path or assign API Key to openai_api_key (not recomended for production)\n",
    "\n",
    "openai_api_key = config['SECRETS']['openai_api_key']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversational Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7aQBoWJqAST93VoAbxiRTcFdTyGQz at 0x24d1c598a90> JSON: {\n",
       "  \"id\": \"chatcmpl-7aQBoWJqAST93VoAbxiRTcFdTyGQz\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1688914836,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"In Python, you can use the `len()` function to get the length of a string. Here's an example:\\n\\n```python\\nstring = \\\"Hello, World!\\\"\\nlength = len(string)\\nprint(length)\\n```\\n\\nOutput:\\n```\\n13\\n```\\n\\nIn this example, the `len()` function is used to get the length of the string \\\"Hello, World!\\\" and store it in the variable `length`. The `print()` function is then used to display the length of the string.\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 53,\n",
       "    \"completion_tokens\": 100,\n",
       "    \"total_tokens\": 153\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_key = openai_api_key\n",
    "\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are helpful learning assitant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"can you help me with python coding problem?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Sure, I’d be happy to help!\"},\n",
    "        {\"role\": \"user\", \"content\": \"How can I get length of a string?\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=100,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In Python, you can use the `len()` function to get the length of a string. Here\\'s an example:\\n\\n```python\\nstring = \"Hello, World!\"\\nlength = len(string)\\nprint(length)\\n```\\n\\nOutput:\\n```\\n13\\n```\\n\\nIn this example, the `len()` function is used to get the length of the string \"Hello, World!\" and store it in the variable `length`. The `print()` function is then used to display the length of the string.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x24d1c01e7a0> JSON: {\n",
       "  \"prompt_tokens\": 53,\n",
       "  \"completion_tokens\": 100,\n",
       "  \"total_tokens\": 153\n",
       "}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['usage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['usage'][\"total_tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Completion Cost = $0.0002795\n"
     ]
    }
   ],
   "source": [
    "# Cost Calculator for GPT-3.5 Turbo\n",
    "input_token_cost = 0.0015/1000\n",
    "output_token_cost = 0.0020/1000\n",
    "\n",
    "cost = response['usage'][\"prompt_tokens\"]*input_token_cost + response['usage'][\"completion_tokens\"]*output_token_cost\n",
    "\n",
    "print(F\"Chat Completion Cost = ${cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercises 1 & 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Print Reponse with proper formatting\n",
    "# Type your code below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Add another chat request asking to modify the script to \n",
    "# return \"large string\" if length > 10 else \"small string\"\n",
    "\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "response =  # COntinue typing your code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-conversation-based Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7aQUkxabzuHnMrWSEU0osj0kAmMG5 at 0x24d7ff40360> JSON: {\n",
       "  \"id\": \"chatcmpl-7aQUkxabzuHnMrWSEU0osj0kAmMG5\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1688916010,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"Sure! Gravity is a force that pulls things towards each other. It's what keeps us on the ground and makes things fall down. You know how when you drop something, like a ball, it falls to the ground? That's because of gravity. Gravity is also what keeps the planets in our solar system orbiting around the sun. It's a really important force that affects everything in the universe!\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 27,\n",
       "    \"completion_tokens\": 81,\n",
       "    \"total_tokens\": 108\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_key = openai_api_key\n",
    "\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are helpful learning assitant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain gravity as a fifth grader?\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=100,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Gravity is a force that pulls things towards each other. It's what keeps us on the ground and makes things fall down. You know how when you drop something, like a ball, it falls to the ground? That's because of gravity. Gravity is also what keeps the planets in our solar system orbiting around the sun. It's a really important force that affects everything in the universe!\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Assistant Function to Help Generaitng Python Programs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_assitant(query):\n",
    "\n",
    "    MODEL = \"gpt-3.5-turbo\"\n",
    "    INSTRUCTIONS = \"\"\"\n",
    "    You are a personal assitant named Chatty helping the user to write python code. \\\n",
    "    Enclose code within ```python and ```. \\\n",
    "    Add [END] after python code.\"\n",
    "    \"\"\".strip()\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": INSTRUCTIONS},\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=200,\n",
    "        stop = \"[END]\"\n",
    "    )\n",
    "    \n",
    "    chat_response = response['choices'][0]['message']['content']\n",
    "    usage = response['usage'].to_dict()\n",
    "\n",
    "    return chat_response, usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Code Generation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_response: Sure! Here's a Python code to calculate the area of a circle:\n",
      "\n",
      "```python\n",
      "import math\n",
      "\n",
      "def calculate_area(radius):\n",
      "    area = math.pi * radius**2\n",
      "    return area\n",
      "\n",
      "radius = float(input(\"Enter the radius of the circle: \"))\n",
      "area = calculate_area(radius)\n",
      "print(\"The area of the circle is:\", area)\n",
      "```\n",
      "\n",
      "\n",
      "usage:{'prompt_tokens': 57, 'completion_tokens': 72, 'total_tokens': 129}\n"
     ]
    }
   ],
   "source": [
    "query = \"Write a Python code to calculate area of a circle?\"\n",
    "\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "chat_response, usage = ask_assitant(query)\n",
    "\n",
    "print(F\"chat_response: {chat_response}\\n\\nusage:{usage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Python Code from the Chat Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import math\n",
      "\n",
      "def calculate_area(radius):\n",
      "    area = math.pi * radius**2\n",
      "    return area\n",
      "\n",
      "radius = float(input(\"Enter the radius of the circle: \"))\n",
      "area = calculate_area(radius)\n",
      "print(\"The area of the circle is:\", area)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "python_code_pattern = r\"```python\\n([\\w\\s\\W]*)```\"\n",
    "python_code = re.findall(python_code_pattern, chat_response)[0]\n",
    "\n",
    "print(python_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute Generated Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area of the circle is: 3.141592653589793\n"
     ]
    }
   ],
   "source": [
    "exec(python_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legacy Completion\n",
    "### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the given text into 1. French, 2. Spanish and 3. Japanese:\n",
      "\n",
      "How much is this milk gallon?\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7aTT0QRmvuXcIYRcC3SWcj8L9rG9W at 0x1c69ea2f1f0> JSON: {\n",
       "  \"id\": \"cmpl-7aTT0QRmvuXcIYRcC3SWcj8L9rG9W\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1688927434,\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"\\n1. Combien co\\u00fbte ce gallon de lait ?\\n2. \\u00bfCu\\u00e1nto cuesta este gal\\u00f3n de leche?\\n3. \\u3053\\u306e\\u30ac\\u30ed\\u30f3\\u306e\\u725b\\u4e73\\u306f\\u3044\\u304f\\u3089\\u3067\\u3059\\u304b\\uff1f\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 28,\n",
       "    \"completion_tokens\": 56,\n",
       "    \"total_tokens\": 84\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_key = openai_api_key\n",
    "MODEL = \"text-davinci-003\"\n",
    "\n",
    "INSTRUCTION = r'Translate the given text into 1. French, 2. Spanish and 3. Japanese:'\n",
    "text = \"How much is this milk gallon?\"\n",
    "\n",
    "prompt = F\"{INSTRUCTION}\\n\\n{text}\\n\\n\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=MODEL,\n",
    "  prompt=prompt,\n",
    "  temperature=0.3,\n",
    "  max_tokens=100,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_response: \n",
      "1. Combien coûte ce gallon de lait ?\n",
      "2. ¿Cuánto cuesta este galón de leche?\n",
      "3. このガロンの牛乳はいくらですか？\n",
      "\n",
      "usage:{'prompt_tokens': 28, 'completion_tokens': 56, 'total_tokens': 84}\n"
     ]
    }
   ],
   "source": [
    "chat_response = response['choices'][0]['text']\n",
    "usage = response['usage'].to_dict()\n",
    "\n",
    "print(F\"chat_response: {chat_response}\\n\\nusage:{usage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "Last update 2023-07-04 by Sumudu Tennakoon\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
